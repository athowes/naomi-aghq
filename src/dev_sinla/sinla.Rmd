---
title: "Implementing simplified INLA"
author:
- name: Adam Howes
output:
  html_document:
    toc: yes
    toc_float: yes
    toc_collapsed: yes
    df_print: paged
    code_folding: show
    theme: lumen
abstract: |
  **Background** Wood (2020) simplify the INLA method by approximating latent field posterior marginals using a reduced cost Laplace approximation which does not rely on sparsity assumptions.
  **Task** We implement the method in R making use of Template Model Builder for Gaussian approximations.
---

We are interested in approximating latent field posterior marginals as follows $p(x_i \, | \, \theta, y) \approx \tilde p(x_i \, | \, \theta, y)$ for each index $i$.
To build up to implementing the simplified INLA approach, we will start with two simpler methods.

# Marginal of joint Gaussian approximation

The `aghq` package currently approximates latent field posterior marginals by taking marginals of the joint Gaussian approximation $p_G(x \, | \, \theta, y)$.
This is same approach used by `method = "gaussian"` in `R-INLA`.
The Gaussian approximation $p_G(x \, | \, \theta, y)$ is previously used in computing the Laplace approximation to $p(\theta \, | \, y)$
\begin{equation}
\tilde p(\theta \, | \, y) \propto \frac{p(x, \theta, y)}{p_G(x \, | \, \theta, y)} \Big\rvert_{x = \hat{\mu}(\theta)} = \frac{p(y, \hat{\mu}(\theta), \theta)}{\det(\hat{Q}(\theta))^{1/2}},
\end{equation}
such that one easy way to calculate it is to use set `random = "x"` in the `TMB` template to integrate the latent field out, then recover the Gaussian approximation from there.

We begin by loading in testing data, as generated by [`prev-anc-art_sim`](https://github.com/athowes/elgm-inf/tree/master/src/prev-anc-art_sim).
`sim_data` contains many replicates of simulated data, so we just take the first one:

```{r}
sim_data <- readRDS("depends/sim_data.rds")
data <- sim_data[[1]]
dat <- list(n = data$n, y_prev = data$y_prev, m_prev = data$m_prev)
```

We create an objective function `f` to evaluate $p(x, \theta, y)$ (without any Laplace approximations!):

```{r}
param <- list(
  beta_prev = 0,
  phi_prev = rep(0, data$n),
  log_sigma_phi_prev = 0
)

compile("model1.cpp")
dyn.load(dynlib("model1"))

f <- MakeADFun(
  data = dat,
  parameters = param,
  DLL = "model1"
)
```

# Full Laplace approximation

Another approach we might take is to calculate the full Laplace approximation
\begin{align}
  \tilde p(x_i \, | \, \theta, y) &\propto \frac{p(x, \theta, y)}{p_G(x_{-i} \, | \, x_i, \theta, y)} \Big\rvert_{x_{-i} = \hat{\mu}_{-i}(x_i, \theta)} \\
  &= \frac{p(y, x_i, \hat{\mu}_{-i}(x_i, \theta), \theta)}{\det(\hat{Q}_{-i}(x_i, \theta))^{1/2}}
\end{align}
This is not practical in some settings as it involves recomputing the Gaussian approximation $p_G(x_{-i} \, | \, x_i, \theta, y)$ for each value of $(x_i, \theta)$ which can be too computationally expensive.
With of a bit of effort, we can implement this in `TMB` by passing in data where elements $i$ and $-i$ of the latent field are named as such (see Appendix for template).

```{r}
compile("model1index.cpp")
dyn.load(dynlib("model1index"))
```

The `prepare_dat` function takes `dat` and makes it compatible with `model1index` for particular choice of marginal `i`.

```{r}
prepare_dat <- function(dat, i) {
  dat[["y_prev_i"]] <- dat$y_prev[i]
  dat[["y_prev_minus_i"]] <- dat$y_prev[-i]
  dat[["m_prev_i"]] <- dat$m_prev[i]
  dat[["m_prev_minus_i"]] <- dat$m_prev[-i]
  dat[c("n", "y_prev_i", "y_prev_minus_i", "m_prev_i", "m_prev_minus_i")]
}
```

Now loop over doing the Laplace approximation for every index.
In the call to `MakeADFun` we set `random = "phi_prev_minus_i"` to integrate all of the random effects but that of the particular index.

```{r}
#' To store obj
template <- list() 

for(i in 1:dat$n) {
  dat_i <- prepare_dat(dat, i)

  #' Starting parameters for TMB are the same for every index of the loop
  param_i <- list(
    beta_prev = 0,
    phi_prev_i = 0,
    phi_prev_minus_i = rep(0, data$n - 1),
    log_sigma_phi_prev = 0
  )

  #' random are integrated out with a Laplace approximation
  obj <- MakeADFun(
    data = dat_i,
    parameters = param_i,
    random = "phi_prev_minus_i",
    DLL = "model1index"
  )

  its <- 1000

  opt <- nlminb(
    start = obj$par,
    objective = obj$fn,
    gradient = obj$gr,
    control = list(iter.max = its, trace = 0)
  )

  sd_out <- sdreport(
    obj,
    par.fixed = opt$par,
    getJointPrecision = TRUE
  )

  template[[i]] <- obj
}
```

```{r}
#' Evaluate objective function at param
f$fn(unlist(param))

transform_param <- function(param) {
  list(
    beta_prev = param$beta_prev,
    phi_prev_i = param$phi_prev[i],
    phi_prev_minus_i = param$phi_prev[-i],
    log_sigma_phi_prev = param$log_sigma_phi_prev
  )
}

param %>%
  transform_param() %>%
  unlist() %>%
  template[[1]]$fn()

#' The mean and precision matrix for the Gaussian approximation to p(x_{-i} | x_i, theta, y)
#' The mean of is length dim
mean <- with(template[[1]]$env, last.par[random])
Q <- template[[1]]$env$spHess(with(template[[1]]$env, last.par), random = TRUE)

#' Numerator of the LA
#' TODO

#' Denominator of the LA
sqrt(det(Q))
```

# Appendix

## `model1.cpp`

```{cpp, echo=TRUE, eval=FALSE, output.var="ex", code=readLines('model1.cpp')}
```

## `model1index.cpp`

```{cpp, echo=TRUE, eval=FALSE, output.var="ex", code=readLines('model1index.cpp')}
```
