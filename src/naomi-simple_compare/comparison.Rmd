---
title: "Inference methods comparison for the simplified Naomi model"
author:
- name: Adam Howes
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    toc_collapsed: yes
    df_print: paged
    code_folding: show
    theme: lumen
abstract: |
  **Background**  We have run the simplified Naomi model using a range of inference methods.
  
  **Task** In this report, we compare the accuracy of the posterior distributions obtained from these inference methods.
---

# Background

We compare the inference results from `TMB`, `aghq` and `tmbstan`.
Import these inference results as follows:

```{r}
tmb <- readRDS("depends/tmb.rds")
aghq <- readRDS("depends/aghq.rds")
adam <- readRDS("depends/adam.rds")
tmbstan <- readRDS("depends/tmbstan.rds")
```

For more information about the conditions under which these results were generated, see:

```{r}
depends <- yaml::read_yaml("orderly.yml")$depends

for(i in seq_along(depends)) {
  report_name <- names(depends[[i]])
  print(paste0("Inference results obtained from ", report_name, " with the query ", depends[[i]][[report_name]]$id))
  report_id <- orderly::orderly_search(query = depends[[i]][[report_name]]$id, report_name)
  print(paste0("Obtained report had ID ", report_id, " and was run with the following parameters:"))
  print(orderly::orderly_info(report_id, report_name)$parameters)
}
```

All of the possible parameter names are as follows:

```{r}
unique(names(tmb$fit$obj$env$par))
```

# Time taken

```{r}
data.frame(
  "TMB" = tmb$time,
  "aghq" = aghq$time,
  "adam" = adam$time,
  "tmbstan" = tmbstan$time
)

adam <- adam$adam
```

# Histogram

```{r}
beta_rho <- histogram_and_ecdf("beta_rho", i = 1, return_df = TRUE)
beta_rho$plot
saveRDS(beta_rho$df, "beta_rho.rds")

histogram_and_ecdf("beta_anc_rho")
```

```{r}
par <- "beta_rho"
i <- 1
par_name <- paste0(par, "[", i, "]")

df_compare <- rbind(
  data.frame(method = "TMB", samples = as.numeric(tmb$fit$sample[[par]][i, ])),
  data.frame(method = "aghq", samples = as.numeric(aghq$quad$sample[[par]][i, ])),
  data.frame(method = "adam", samples = as.numeric(adam$sample[[par]][i, ])),
  data.frame(method = "tmbstan", samples = as.numeric(unlist(rstan::extract(tmbstan$mcmc, pars = par)[[par]][, i])))
)

grid <- seq(from = min(df_compare$samples), to = max(df_compare$samples), by = 0.1)

tmb_ecdf <- stats::ecdf(filter(df_compare, method == "TMB") %>% pull(samples))
tmb_ecdf_df <- data.frame(x = grid, ecdf = tmb_ecdf(grid), method = "TMB")

aghq_ecdf <- stats::ecdf(filter(df_compare, method == "aghq") %>% pull(samples))
aghq_ecdf_df <- data.frame(x = grid, ecdf = aghq_ecdf(grid), method = "aghq")

adam_ecdf <- stats::ecdf(filter(df_compare, method == "adam") %>% pull(samples))
adam_ecdf_df <- data.frame(x = grid, ecdf = adam_ecdf(grid), method = "adam")
 
tmbstan_ecdf <- stats::ecdf(filter(df_compare, method == "tmbstan") %>% pull(samples))
tmbstan_ecdf_df <- data.frame(x = grid, ecdf = tmbstan_ecdf(grid), method = "tmbstan")

bind_rows(tmb_ecdf_df, aghq_ecdf_df, adam_ecdf_df, tmbstan_ecdf_df) %>%
  mutate(method = forcats::fct_relevel(method, levels = c("TMB", "aghq", "adam", "tmbstan"))) %>%
  ggplot(aes(x = x, y = ecdf, col = method)) +
    geom_line() +
    scale_color_manual(values = multi.utils::cbpalette()) +
    labs(x = "", y = "ECDF") +
    theme_minimal()

```


# KS

## Individual parameters

```{r}
ks_helper <- function(par, ...) {
  to_ks_df(par) %>% ks_plot(par, ...)
}

ks_helper("beta")
ks_helper("logit")
ks_helper("log_sigma")

ks_helper("u_rho_x")
ks_helper("u_rho_x", method1 = "TMB", method2 = "adam")

ks_helper("u_rho_xs")
ks_helper("u_rho_xs", method1 = "TMB", method2 = "adam")

ks_helper("us_rho_x")
ks_helper("us_rho_x", method1 = "TMB", method2 = "adam")

ks_helper("us_rho_xs")
ks_helper("us_rho_xs", method1 = "TMB", method2 = "adam")

ks_helper("u_rho_a")
ks_helper("u_rho_a", method1 = "TMB", method2 = "adam")

ks_helper("u_rho_as")
ks_helper("u_rho_as", method1 = "TMB", method2 = "adam")

ks_helper("u_alpha_x")
ks_helper("u_alpha_x", method1 = "TMB", method2 = "adam")

ks_helper("u_alpha_xs")
ks_helper("u_alpha_xs", method1 = "TMB", method2 = "adam")

ks_helper("us_alpha_x")
ks_helper("us_alpha_x", method1 = "TMB", method2 = "adam")

ks_helper("us_alpha_xs")
ks_helper("us_alpha_xs", method1 = "TMB", method2 = "adam")

ks_helper("u_alpha_a")
ks_helper("u_alpha_a", method1 = "TMB", method2 = "adam")

ks_helper("u_alpha_as")
ks_helper("u_alpha_as", method1 = "TMB", method2 = "adam")

ks_helper("u_alpha_xa")
ks_helper("u_alpha_xa", method1 = "TMB", method2 = "adam")

ks_helper("ui_anc_rho_x")
ks_helper("ui_anc_rho_x", method1 = "TMB", method2 = "adam")

ks_helper("ui_anc_alpha_x")
ks_helper("ui_anc_alpha_x", method1 = "TMB", method2 = "adam")

ks_helper("log_or_gamma")
ks_helper("log_or_gamma", method1 = "TMB", method2 = "adam")
```

## Summary table

```{r}
ks_summary <- lapply(unique(names(tmb$fit$obj$env$par)), function(x) {
  to_ks_df(x) %>%
    group_by(method) %>%
    summarise(ks = mean(ks), par = x)
}) %>%
  bind_rows() %>%
  pivot_wider(names_from = "method", values_from = "ks") %>%
  rename(
    "Parameter" = "par",
    "KS(aghq, tmbstan)" = "aghq",
    "KS(TMB, tmbstan)" = "TMB",
  )

ks_summary %>%
  gt::gt() %>%
  gt::fmt_number(
    columns = starts_with("KS"),
    decimals = 3
  )

ggplot(ks_summary, aes(x = `KS(TMB, tmbstan)`, y = `KS(aghq, tmbstan)`)) +
  geom_point(alpha = 0.5) +
  xlim(0, 1) +
  ylim(0, 1) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  labs(x = "KS(TMB, tmbstan)", y = "KS(aghq, tmbstan)") +
  theme_minimal() 

ks_summary %>%
  mutate(`KS difference` = `KS(TMB, tmbstan)` - `KS(aghq, tmbstan)`) %>%
  ggplot(aes(x = `KS difference`)) +
    geom_boxplot(width = 0.5) +
    coord_flip() +
    labs(x = "KS(TMB, tmbstan) - KS(aghq, tmbstan)") +
    theme_minimal()
```

## Investigation into large KS values

The following parameters have KS values greater than 0.5 in both dimensions.

```{r}
(big_ks <- ks_summary %>%
  filter(`KS(aghq, tmbstan)` + `KS(TMB, tmbstan)` > 0.5) %>%
  pull(Parameter))
```

Let's look into this further by plotting the histograms:

```{r}
lapply(big_ks, histogram_plot)
```

# MMD

```{r}
#' To write!
```

# PSIS

Suppose we have two sets of samples from the posterior.
For each sample we are going to want to evaluate the log-likelihood, so that we can calculate the log-likelihood ratios.
We can extract the `TMB` objective function for the log-likelihood as follows:

```{r}
tmb$fit$obj$fn()
```
