---
title: "Inference methods comparison for the simplified Naomi model"
author:
- name: Adam Howes
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    toc_collapsed: yes
    df_print: paged
    code_folding: show
    theme: lumen
abstract: |
  **Background**  We have run the simplified Naomi model using a range of inference methods.
  
  **Task** In this report, we compare the accuracy of the posterior distributions obtained from these inference methods.
---

# Background

We compare the inference results from `TMB`, `aghq` and `tmbstan`.
Import these inference results as follows:

```{r}
tmb <- readRDS("depends/tmb.rds")
aghq <- readRDS("depends/aghq.rds")
tmbstan <- readRDS("depends/tmbstan.rds")
```

For more information about the conditions under which these results were generated, see:

```{r}
depends <- yaml::read_yaml("orderly.yml")$depends

for(i in seq_along(depends)) {
  report_name <- names(depends[[i]])
  print(paste0("Inference results obtained from ", report_name, " with the query ", depends[[i]][[report_name]]$id))
  report_id <- orderly::orderly_search(query = depends[[i]][[report_name]]$id, report_name)
  print(paste0("Obtained report had ID ", report_id, " and was run with the following parameters:"))
  print(orderly::orderly_info(report_id, report_name)$parameters)
}
```

All of the possible parameter names are as follows:

```{r}
unique(names(tmb$fit$obj$env$par))
```

# Time taken

```{r}
data.frame(
  "TMB" = tmb$time,
  "aghq" = aghq$time,
  "tmbstan" = tmbstan$time
)
```

# Histogram

```{r}
histogram_plot("beta_anc_rho")
```

# KS

## Individual parameters

```{r}
ks_helper <- function(par) to_ks_df(par) %>% ks_plot(par = par)

ks_helper("beta")
ks_helper("logit")
ks_helper("log_sigma")

ks_helper("u_rho_x")
ks_helper("u_rho_xs")
ks_helper("us_rho_x")
ks_helper("us_rho_xs")
ks_helper("u_rho_a")
ks_helper("u_rho_as")

ks_helper("u_alpha_x")
ks_helper("u_alpha_xs")
ks_helper("us_alpha_x")
ks_helper("us_alpha_xs")
ks_helper("u_alpha_a")
ks_helper("u_alpha_as")
ks_helper("u_alpha_xa")

ks_helper("ui_anc_rho_x")
ks_helper("ui_anc_alpha_x")
ks_helper("log_or_gamma")
```

## Summary table

```{r}
ks_summary <- lapply(unique(names(tmb$fit$obj$env$par)), function(x) {
  to_ks_df(x) %>%
    group_by(method) %>%
    summarise(ks = mean(ks), par = x)
}) %>%
  bind_rows() %>%
  pivot_wider(names_from = "method", values_from = "ks") %>%
  rename(
    "Parameter" = "par",
    "KS(aghq, tmbstan)" = "aghq",
    "KS(TMB, tmbstan)" = "TMB",
  )

ks_summary %>%
  gt::gt() %>%
  gt::fmt_number(
    columns = starts_with("KS"),
    decimals = 3
  )

ggplot(ks_summary, aes(x = `KS(TMB, tmbstan)`, y = `KS(aghq, tmbstan)`)) +
  geom_point(alpha = 0.5) +
  xlim(0, 1) +
  ylim(0, 1) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  labs(x = "KS(aghq, tmbstan)", y = "KS(TMB, tmbstan)") +
  theme_minimal() 

ks_summary %>%
  mutate(`KS difference` = `KS(TMB, tmbstan)` - `KS(aghq, tmbstan)`) %>%
  ggplot(aes(x = `KS difference`)) +
    geom_boxplot(width = 0.5) +
    coord_flip() +
    labs(x = "KS(TMB, tmbstan) - KS(aghq, tmbstan)") +
    theme_minimal()
```

# MMD

```{r}
#' To write!
```

# PSIS

Suppose we have two sets of samples from the posterior.
For each sample we are going to want to evaluate the log-likelihood, so that we can calculate the log-likelihood ratios.
We can extract the `TMB` objective function for the log-likelihood as follows:

```{r}
tmb$fit$obj$fn()
```
