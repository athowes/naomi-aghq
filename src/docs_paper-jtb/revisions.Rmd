---
title: Response to reviewers
author:
  - Adam Howes^[Department of Mathematics, Imperial College London]
  - Alex Stringer^[Department of Statistics and Actuarial Science, University of Waterloo]
  - Seth R. Flaxman^[Department of Computer Science, Oxford University]
  - Jeffrey W. Imai-Eaton^[Harvard T.H. Chan School of Public Health, Harvard University]
output:
  bookdown::pdf_document2:
    toc: no
    number_sections: yes
    keep_tex: yes
bibliography: citations.bib
header-includes:
  \usepackage{xr} \externaldocument{paper}
---

```{r echo = FALSE, message = FALSE}
library(dplyr)

options(scipen = 100)

knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  dpi = 320,
  cache = TRUE,
  out.width = "95%",
  fig.align = "center",
  fig.pos = "!h",
  out.extra = ""
)

knitr::opts_chunk$set()
```

Thank you for taking the time to read and review our paper "Fast approximate Bayesian inference of HIV indicators using PCA adaptive Gauss-Hermite quadrature".
In what follows we address your comments and suggestions point by point.
We appreciate the feedback to improve the work and have made the relevant changes to the manuscript.

\clearpage

# Reviewer 1 {-}

> On `tmbstan` as compared with e.g. `rstan`

`tmbstan` passes the objective function and its gradient (calculated in `TMB`) directly to `rstan` via the [`op_matrix_vari`](https://mc-stan.org/math/classstan_1_1math_1_1op__matrix__vari.html).
As such, the NUTS algorithm used should be the same.
Nonetheless, it could be that there are speed differences between function evaluations in `TMB` and Stan.
We have added a sentence to the discussion noting this possible comparison: "Additionally, direct implementation of Naomi within the Stan PPL could alter the speed by as much as plus or minus 50% [@monnahan2018no] and would give access to other algorithms implemented in Stan such as variational inference [@kucukelbir2015automatic] and Pathfinder [@zhang2022pathfinder]."

> Questions about the HIV model

Jeff broadly agrees with the reviewer.
(This is an area of current work on Naomi extension.)

> Selecting dimensions in proportion to variance in some outcome explained

It is possible to obtain derivative information about a quantity in a `TMB` model using `ADREPORT`.

> Bayesian optimisation as a competitor in the space

The goal of Bayesian optimisation (BO) is to find the maximum of a (black box) function.
For this reason, we do not see BO as a competitor to algorithms (like ours) intended to perform Bayesian inference.
(One could imagine using BO to optimise the hyperparameters, however it would be preferable to use gradients [as they are available].)

> Typos spotted

Thank you for spotting these two typographic errors.
We have corrected them in the manuscript.

# Reviewer 2 {-}

> On Figure 5

Thank you for the suggestion.
We have adjusted the `alpha` value from 0.5 to 0.1 and added a caption to the figure explaining the possible overlap to make the figure clearer:

```{r}
knitr::include_graphics("revisions/fig5_edit.png")
```

> On Figure 6

Yes that is correct, it's the NUTS estimate minus the GEB or GPCA-AGHQ estimate.
We have clarified the $y$-axis here (and where relevant throughout the manuscript) to read "Absolute difference (NUTS - method)".

> On Figure 7

We agree that there are too many colours here for this figure to be clear, and that the suggestion to split the figure across panels is a good one.
To do so, we have grouped the parameters by the model component (e.g. HIV prevalence), and used colour to represent the type of parameter (e.g. intecept).

```{r}
knitr::include_graphics("depends/ks-summary.png")
```

> ...the method is tunable with how many PCA components are selected and what value of $k$ to use...

We agree that it would be of interest to explore the effect of choosing a different number of PCA components ($s$) and number of quadrature points per dimension ($k$).
One could also consider a varying number of quadrature points.
For example "gradually lowering $k$ over the principal components" presumably would be the most efficient approach.

> ...a useful intermediate scheme to me seems to be to drop the corners of the grid...

We agree that this could be a useful approach.
Indeed Section 6.1.2. reads "Finally, it is likely possible to achieve better performance by pruning and prerotation of the quadrature grid, as discussed by @jackel2005note.".
We believe the suggested approach is what we refer to here (very briefly) as "pruning".
To clarify this point, we have rewritten this sentence as: "Finally, it is likely possible to achieve better performance by pruning (dropping points where the weight is below some threshold) or prerotation (before adaption, in order to e.g. achieve better coverage along the principal axis) of the quadrature grid [@jackel2005note].".

# References {#references .unnumbered}
